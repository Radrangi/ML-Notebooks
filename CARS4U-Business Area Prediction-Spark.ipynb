{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "<table style=\"border: none\" align=\"left\">\n    <tr style=\"border: none\">\n       <th style=\"border: none\"><img src=\"https://raw.githubusercontent.com/pmservice/cars-4-you/master/static/images/logo.png\" width=\"200\" alt=\"Icon\"></th>\n       <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Business Area Prediction</b></th>\n   </tr>\n</table>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<img align=left src=\"https://github.com/pmservice/cars-4-you/raw/master/static/images/business_area.png\" width=\"560\" alt=\"Icon\">\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Contents\n- [0. Setup](#setup)\n- [1. Introduction](#introduction)\n- [2. Load and explore data](#load)\n- [3. Create an Apache Spark machine learning model](#model)\n- [4. Store the model in the Watson Machine Learning repository](#persistence)\n- [5. Deploy the model in the IBM Cloud](#deployment)\n- [6. Payload logging for Spark model](#payload_logging)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**Note:** This notebook works correctly with kernel `Python 3.5 with Spark 2.1`, please **do not change kernel**.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"setup\"></a>\n## 0. Setup\n\nIn this section please use below cell to upgrade the `watson-machine-learning-client`.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!rm -rf $PIP_BUILD/watson-machine-learning-client\n!pip install --upgrade watson-machine-learning-client", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Requirement already up-to-date: watson-machine-learning-client in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages\nRequirement already up-to-date: tqdm in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement already up-to-date: tabulate in /usr/local/src/conda3_runtime.v37/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement already up-to-date: urllib3 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement already up-to-date: certifi in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement already up-to-date: pandas in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement already up-to-date: lomond in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement already up-to-date: ibm-cos-sdk in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement already up-to-date: requests in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement already up-to-date: pytz>=2011k in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\nRequirement already up-to-date: numpy>=1.9.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\nRequirement already up-to-date: python-dateutil>=2.5.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\nRequirement already up-to-date: six>=1.10.0 in /usr/local/src/conda3_runtime.v37/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from lomond->watson-machine-learning-client)\nRequirement already up-to-date: ibm-cos-sdk-core==2.*,>=2.0.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client)\nRequirement already up-to-date: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client)\nRequirement already up-to-date: chardet<3.1.0,>=3.0.2 in /usr/local/src/conda3_runtime.v37/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from requests->watson-machine-learning-client)\nRequirement already up-to-date: idna<2.8,>=2.5 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from requests->watson-machine-learning-client)\nRequirement already up-to-date: docutils>=0.10 in /usr/local/src/conda3_runtime.v37/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client)\nRequirement already up-to-date: jmespath<1.0.0,>=0.7.1 in /usr/local/src/conda3_runtime.v37/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client)\n"
                }
            ], 
            "execution_count": 54
        }, 
        {
            "source": "**Note**: Please restart the kernel (Kernel -> Restart)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"introduction\"></a>\n## 1. Introduction\n\nThis notebook creates a spark mllib model to predict Business Area based on client feedback. The notebook shows how to train, store and deploy a model  for scoring.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"load\"></a>\n## 2. Load and explore data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this section you will load the data as an Apache Spark DataFrame and perform a basic exploration.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Read data into Spark DataFrame from DB2 database and show sample record.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n\n# @hidden_cell\n# The following code is used to access your data and contains your credentials.\n# You might want to remove those credentials before you share your notebook.\n\nproperties_db2 = {\n    'driver': 'com.ibm.db2.jcc.DB2Driver',\n    'jdbcurl': 'jdbc:db2://dashdb-entry-yp-dal10-01.services.dal.bluemix.net:50000/BLUDB',\n    'user': 'dash5120',\n    'password': 'G5_CehiL4_Ux'\n}\n\ntable_name = 'CAR_RENTAL_TRAINING'\ndf_data = spark.read.jdbc(properties_db2['jdbcurl'], table='.'.join([properties_db2['user'], table_name]), properties=properties_db2)\ndf_data.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Row(ID=2805, Gender='Male', Status='S', Children=1, Age=Decimal('43.91'), Customer_Status='Active', Car_Owner='Yes', Customer_Service='The rental clerk was nice, but I swear she was deaf.  We had to repeat everything twice and although we had a reservation she treated us like a walk in, so that all the information that we gave to reserve the car we had to repeat all over again.', Satisfaction=0, Business_Area='Service: Knowledge', Action='On-demand pickup location')"
                    }, 
                    "execution_count": 93, 
                    "metadata": {}
                }
            ], 
            "execution_count": 93
        }, 
        {
            "source": "**Tip:** Code above can be inserted using Data menu.  You have to select `Insert SparkSession DataFrame` option.\n\n**Note:** Inserted code is modified to work with code in cells below.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "As you can see, the data contains eleven fields. `Business_Area` field is the one you would like to predict using feedback data in `Customer_Service` field.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "print(\"Number of records: \" + str(df_data.count()))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of records: 486\n"
                }
            ], 
            "execution_count": 94
        }, 
        {
            "source": "Let's see distribution of target field.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df_data.select('Business_Area').groupBy('Business_Area').count().show(truncate=False)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+----------------------------------+-----+\n|Business_Area                     |count|\n+----------------------------------+-----+\n|Service: Accessibility            |26   |\n|Product: Functioning              |150  |\n|Service: Attitude                 |24   |\n|Service: Orders/Contracts         |32   |\n|Product: Availability/Variety/Size|42   |\n|Product: Pricing and Billing      |24   |\n|Product: Information              |8    |\n|Service: Knowledge                |180  |\n+----------------------------------+-----+\n\n"
                }
            ], 
            "execution_count": 95
        }, 
        {
            "source": "<a id=\"model\"></a>\n## 3. Create an Apache Spark machine learning model\n\nIn this section you will learn how to:\n\n- [3.1 Prepare data for model training and evaluation](#prep)\n- [3.2 Create an Apache Spark machine learning pipeline](#pipe)\n- [3.3 Train a model](#train)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"prep\"></a>\n### 3.1 Prepare data for model training and evaluation\n\nIn this subsection you will split your data into: train and test data set.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "train_data, test_data = df_data.select(\"ID\", \"Customer_Service\", \"Business_Area\").randomSplit([0.8, 0.2], 24)\n\nprint(\"Number of training records: \" + str(train_data.count()))\nprint(\"Number of testing records : \" + str(test_data.count()))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "### 3.2 Create the pipeline<a id=\"pipe\"></a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this section you will create an Apache Spark machine learning pipeline and then train the model.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from pyspark.ml.feature import StringIndexer, IndexToString, HashingTF, IDF, Tokenizer\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml import Pipeline, Model\nfrom pyspark.sql.types import *", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 96
        }, 
        {
            "source": "In the first data preprocessing step, create features from `Customer_Service` field.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "tokenizer = Tokenizer(inputCol=\"Customer_Service\", outputCol=\"words\")\nhashing_tf = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol='hash')\nidf = IDF(inputCol=hashing_tf.getOutputCol(), outputCol=\"features\", minDocFreq=5)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 97
        }, 
        {
            "source": "In the following step, use the StringIndexer transformer to convert `Business_Area` to numeric.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "string_indexer_label = StringIndexer(inputCol=\"Business_Area\", outputCol=\"label\").fit(train_data)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 98
        }, 
        {
            "source": "Add decision tree model to predict `Business_Area`.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "dt_area = DecisionTreeClassifier(labelCol=\"label\", featuresCol=idf.getOutputCol())", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 99
        }, 
        {
            "source": "Finally, setup transformer to convert the indexed labels back to original labels.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "label_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=string_indexer_label.labels)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 100
        }, 
        {
            "source": "pipeline = Pipeline(stages=[tokenizer, hashing_tf, idf, string_indexer_label, dt_area, label_converter])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 101
        }, 
        {
            "source": "### 3.3 Train the model<a id=\"train\"></a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this subsection you will train model and evaluate its accuracy.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "model = pipeline.fit(train_data)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 102
        }, 
        {
            "source": "predictions = model.transform(test_data)\npredictions.select('Customer_Service','Business_Area','predictedLabel').show(3)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------------------+--------------------+------------------+\n|    Customer_Service|       Business_Area|    predictedLabel|\n+--------------------+--------------------+------------------+\n|Agents always wan...|   Service: Attitude|Service: Knowledge|\n|Did not have some...|Service: Accessib...|Service: Knowledge|\n|I was penalty cha...|Product: Pricing ...|Service: Knowledge|\n+--------------------+--------------------+------------------+\nonly showing top 3 rows\n\n"
                }
            ], 
            "execution_count": 103
        }, 
        {
            "source": "predictions.printSchema()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- ID: integer (nullable = true)\n |-- Customer_Service: string (nullable = true)\n |-- Business_Area: string (nullable = true)\n |-- words: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- hash: vector (nullable = true)\n |-- features: vector (nullable = true)\n |-- label: double (nullable = true)\n |-- rawPrediction: vector (nullable = true)\n |-- probability: vector (nullable = true)\n |-- prediction: double (nullable = true)\n |-- predictedLabel: string (nullable = true)\n\n"
                }
            ], 
            "execution_count": 104
        }, 
        {
            "source": "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\n\nprint(\"Accuracy = %3.2f\" % accuracy)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Accuracy = 0.49\n"
                }
            ], 
            "execution_count": 105
        }, 
        {
            "source": "**Note:** Accuracy of the model is low, however based on customer comment more than one Business Area could be selected. In such cases top k (for example k=3) would be more suited for model evaluation.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"persistence\"></a>\n## 4. Store the model in the repository", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "In this section you will store trained model to Watson Machine Learning repository. When model is stored some metada is optional, however we provide it to be able to configure Continuous Learning System.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 106
        }, 
        {
            "source": "We need Watson Machine Learning credentials to be able to store model in repository.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# @hidden_cell\n# How to get associated service credentials\n\nwml_credentials = {\n  \"instance_id\": \"000263d8-04e0-4060-ad69-fcfe40069018\",\n  \"password\": \"7419325b-3de4-476c-94cb-4b158fa335b0\",\n  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n  \"username\": \"cdc4b5da-8380-42f1-bd82-da044b283959\"\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 107
        }, 
        {
            "source": "client = WatsonMachineLearningAPIClient(wml_credentials)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 108
        }, 
        {
            "source": "client.version", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "'1.0.260'"
                    }, 
                    "execution_count": 109, 
                    "metadata": {}
                }
            ], 
            "execution_count": 109
        }, 
        {
            "source": "Use code in cell below to store model in Watson Machine Learning repository.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "published_model_details = client.repository.store_model(model=model, meta_props={'name':'CARS4U - Business Area Prediction Model'}, training_data=train_data, pipeline=pipeline)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 110
        }, 
        {
            "source": "model_uid = client.repository.get_model_uid(published_model_details)\nprint(model_uid)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "ef914435-09d3-4fc5-a637-8958f1ade572\n"
                }
            ], 
            "execution_count": 111
        }, 
        {
            "source": "<a id=\"deploy\"></a>\n## 5. Deploy model in the IBM Cloud", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this section you will learn how to create model deployment in the IBM Cloud and retreive information about scoring endpoint.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "deployment_details = client.deployments.create(asset_uid=model_uid, name='CARS4U - Business Area Prediction Model Deployment')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "You can use deployed model to score new data using scoring endpoint. You can use following command to get scoring endpoint.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "scoring_url = client.deployments.get_scoring_url(deployment_details)\nprint(scoring_url)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "https://us-south.ml.cloud.ibm.com/v3/wml_instances/000263d8-04e0-4060-ad69-fcfe40069018/deployments/86837723-331c-4fb7-a60e-c858c734d74a/online\n"
                }
            ], 
            "execution_count": 112
        }, 
        {
            "source": "<a id=\"payload_logging\"></a>\n## 6. Payload logging", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this section we configure payload logging for online scoring.\n\nn this section you will learn how to:\n\n- [6.1 Payload_logging setup](#payload_logging_setup)\n- [6.2 Payload logging with transaction ID](#payload_logging_scoring)\n- [6.3 Scoring](#scoring)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"payload_logging_setup\"></a>\n### 6.1. Setup", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "We have to get `deployment_uid` for model deployed in the IBM Cloud.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "deployment_uid = client.deployments.get_uid(deployment_details)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 113
        }, 
        {
            "source": "We need to provide configuration for database to which scoring payload will be logged.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# @hidden_cell\npostgres_connection = {\n  'database':'compose',\n  'password':\"\"\"WHDHTGJYSXKJTMET\"\"\",\n  'port':'47860',\n  'host':'sl-us-south-1-portal.28.dblayer.com',\n  'username':'admin'\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 114
        }, 
        {
            "source": "**Tip:** You can use Data panel to insert postgress connection credentials.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "payload_data_reference = {\n    \"type\": \"postgresql\",\n    \"location\": {\n        \"tablename\": \"public.cars4u_business_area_prediction_payload\"\n    },\n    \"connection\": {\n            \"uri\": \"postgres://{username}:{password}@{host}:{port}/{database}\".format(**postgres_connection)\n        }\n}\nprint(payload_data_reference)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "{'connection': {'uri': 'postgres://admin:WHDHTGJYSXKJTMET@sl-us-south-1-portal.28.dblayer.com:47860/compose'}, 'location': {'tablename': 'public.cars4u_business_area_prediction_payload'}, 'type': 'postgresql'}\n"
                }
            ], 
            "execution_count": 115
        }, 
        {
            "source": "payload_metadata = {client.deployments.PayloadLoggingMetaNames.PAYLOAD_DATA_REFERENCE: payload_data_reference}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 116
        }, 
        {
            "source": "Now we are ready to setup payload logging for deployed model.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "config_details = client.deployments.setup_payload_logging(deployment_uid, meta_props=payload_metadata)\nprint(config_details)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "{'dynamic_schema_update': False, 'payload_store': {'connection': {'host': 'sl-us-south-1-portal.28.dblayer.com:47860', 'db': 'compose', 'uri': 'postgres://admin:WHDHTGJYSXKJTMET@sl-us-south-1-portal.28.dblayer.com:47860/compose'}, 'location': {'tablename': 'public.cars4u_business_area_prediction_payload'}, 'type': 'postgresql'}, 'output_data_schema': {'fields': [{'metadata': {'name': 'ID', 'scale': 0}, 'type': 'integer', 'name': 'ID', 'nullable': True}, {'metadata': {'name': 'Customer_Service', 'scale': 0}, 'type': 'string', 'name': 'Customer_Service', 'nullable': True}, {'metadata': {'modeling_role': 'prediction'}, 'type': 'double', 'name': 'prediction', 'nullable': True}, {'metadata': {'modeling_role': 'prediction-probability'}, 'type': 'double', 'name': 'prediction_probability', 'nullable': True}, {'metadata': {'modeling_role': 'probability'}, 'type': {'containsNull': True, 'elementType': 'double', 'type': 'array'}, 'name': 'probability', 'nullable': True}], 'type': 'struct'}}\n"
                }
            ], 
            "execution_count": 117
        }, 
        {
            "source": "<a id=\"payload_logging_scoring\"></a>\n### 6.2. Payload logging with transaction ID", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Here we present how to add transaction ID to payload logging.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import uuid\n\nscoring_request_payload = {\n    \"fields\": [\"ID\",\"Customer_Service\"],\n    \"values\": [[1,'Although there were no available car in category stuff assisted in finding an available vehicle.'],\n               [2,'Car rental cost was higher because I decided to pay cash'],\n               [3,'Do not try sell what I do not need.']]\n}\n\ntransaction_id = 'transaction-id-' + uuid.uuid4().hex\nprint(\"Transaction ID:\", transaction_id)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Transaction ID: transaction-id-44ad66ad71fe453eb995cd1e63eed22f\n"
                }
            ], 
            "execution_count": 118
        }, 
        {
            "source": "Now we are ready to send scoring request with transaction ID.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"scoring\"></a>\n### 6.3. Scoring", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Scoring with transaction ID.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "scoring_response = client.deployments.score(scoring_url, scoring_request_payload, transaction_id=transaction_id)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 126
        }, 
        {
            "source": "Scoring without transaction ID.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import json\n\nscoring_response = client.deployments.score(scoring_url, scoring_request_payload)\n\nprint(json.dumps(scoring_response, indent=3))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "{\n   \"fields\": [\n      \"ID\",\n      \"Customer_Service\",\n      \"Business_Area\",\n      \"words\",\n      \"hash\",\n      \"features\",\n      \"label\",\n      \"rawPrediction\",\n      \"probability\",\n      \"prediction\",\n      \"predictedLabel\"\n   ],\n   \"values\": [\n      [\n         1,\n         \"Although there were no available car in category stuff assisted in finding an available vehicle.\",\n         \"Product: Functioning\",\n         [\n            \"although\",\n            \"there\",\n            \"were\",\n            \"no\",\n            \"available\",\n            \"car\",\n            \"in\",\n            \"category\",\n            \"stuff\",\n            \"assisted\",\n            \"in\",\n            \"finding\",\n            \"an\",\n            \"available\",\n            \"vehicle.\"\n         ],\n         [\n            262144,\n            [\n               33209,\n               56750,\n               58227,\n               68435,\n               92612,\n               156250,\n               180535,\n               194536,\n               222453,\n               229772,\n               238163,\n               253170,\n               253518\n            ],\n            [\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               2.0,\n               1.0,\n               2.0,\n               1.0,\n               1.0\n            ]\n         ],\n         [\n            262144,\n            [\n               33209,\n               56750,\n               58227,\n               68435,\n               92612,\n               156250,\n               180535,\n               194536,\n               222453,\n               229772,\n               238163,\n               253170,\n               253518\n            ],\n            [\n               0.0,\n               0.0,\n               0.0,\n               0.0,\n               0.0,\n               2.2671831659431296,\n               2.569464037816063,\n               2.8377280244107426,\n               3.8123396408115986,\n               0.9483300856187717,\n               7.221835825288449,\n               1.2437942985126076,\n               0.0\n            ]\n         ],\n         0.0,\n         [\n            45.0,\n            72.0,\n            6.0,\n            10.0,\n            10.0,\n            9.0,\n            5.0,\n            3.0\n         ],\n         [\n            0.28125,\n            0.45,\n            0.0375,\n            0.0625,\n            0.0625,\n            0.05625,\n            0.03125,\n            0.01875\n         ],\n         1.0,\n         \"Service: Knowledge\"\n      ],\n      [\n         2,\n         \"Car rental cost was higher because I decided to pay cash\",\n         \"Product: Functioning\",\n         [\n            \"car\",\n            \"rental\",\n            \"cost\",\n            \"was\",\n            \"higher\",\n            \"because\",\n            \"i\",\n            \"decided\",\n            \"to\",\n            \"pay\",\n            \"cash\"\n         ],\n         [\n            262144,\n            [\n               24417,\n               25570,\n               42742,\n               95547,\n               122925,\n               146794,\n               159775,\n               167404,\n               205044,\n               229772,\n               262014\n            ],\n            [\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0,\n               1.0\n            ]\n         ],\n         [\n            262144,\n            [\n               24417,\n               25570,\n               42742,\n               95547,\n               122925,\n               146794,\n               159775,\n               167404,\n               205044,\n               229772,\n               262014\n            ],\n            [\n               1.0588719600185956,\n               0.8808888048232392,\n               2.0353815518858056,\n               3.100092288878234,\n               3.20545280453606,\n               0.0,\n               0.0,\n               0.0,\n               0.6752895631599388,\n               0.9483300856187717,\n               0.0\n            ]\n         ],\n         0.0,\n         [\n            0.0,\n            0.0,\n            3.0,\n            0.0,\n            0.0,\n            0.0,\n            0.0,\n            0.0\n         ],\n         [\n            0.0,\n            0.0,\n            1.0,\n            0.0,\n            0.0,\n            0.0,\n            0.0,\n            0.0\n         ],\n         2.0,\n         \"Product: Availability/Variety/Size\"\n      ],\n      [\n         3,\n         \"Do not try sell what I do not need.\",\n         \"Product: Functioning\",\n         [\n            \"do\",\n            \"not\",\n            \"try\",\n            \"sell\",\n            \"what\",\n            \"i\",\n            \"do\",\n            \"not\",\n            \"need.\"\n         ],\n         [\n            262144,\n            [\n               24417,\n               37470,\n               79875,\n               81566,\n               123445,\n               139098,\n               141407\n            ],\n            [\n               1.0,\n               2.0,\n               1.0,\n               1.0,\n               1.0,\n               2.0,\n               1.0\n            ]\n         ],\n         [\n            262144,\n            [\n               24417,\n               37470,\n               79875,\n               81566,\n               123445,\n               139098,\n               141407\n            ],\n            [\n               1.0588719600185956,\n               0.0,\n               0.0,\n               3.4567672328169663,\n               0.0,\n               3.8123396408115986,\n               3.6109179126442243\n            ]\n         ],\n         0.0,\n         [\n            45.0,\n            72.0,\n            6.0,\n            10.0,\n            10.0,\n            9.0,\n            5.0,\n            3.0\n         ],\n         [\n            0.28125,\n            0.45,\n            0.0375,\n            0.0625,\n            0.0625,\n            0.05625,\n            0.03125,\n            0.01875\n         ],\n         1.0,\n         \"Service: Knowledge\"\n      ]\n   ]\n}\n"
                }
            ], 
            "execution_count": 125
        }, 
        {
            "source": "---", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}