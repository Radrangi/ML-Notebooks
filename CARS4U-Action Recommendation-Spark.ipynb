{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "<table style=\"border: none\" align=\"left\">\n    <tr style=\"border: none\">\n       <th style=\"border: none\"><img src=\"https://raw.githubusercontent.com/pmservice/cars-4-you/master/static/images/logo.png\" width=\"200\" alt=\"Icon\"></th>\n       <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Action Recommendation</b></th>\n   </tr>\n</table>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<img align=left src=\"https://github.com/pmservice/cars-4-you/raw/master/static/images/action.png\" width=\"550\" alt=\"Icon\">", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Contents\n- [0. Setup](#setup)\n- [1. Introduction](#introduction)\n- [2. Load and explore data](#load)\n- [3. Create an Apache Spark machine learning model](#model)\n- [4. Store the model in the Watson Machine Learning repository](#persistence)\n- [5. Deploy the model in the IBM Cloud](#persistence)\n- [6. Configure payload logging](#logging)\n- [7. Configure continous learning system](#learning)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**Note:** This notebook works correctly with kernel `Python 3.5 with Spark 2.1`, please **do not change kernel**.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"setup\"></a>\n## 0. Setup\n\nIn this section please use below cell to upgrade the `watson-machine-learning-client`.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!rm -rf $PIP_BUILD\n!pip install --upgrade watson-machine-learning-client==1.0.260", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Requirement already up-to-date: watson-machine-learning-client==1.0.260 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages\nRequirement already up-to-date: tqdm in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: tabulate in /usr/local/src/conda3_runtime.v37/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: urllib3 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: certifi in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: pandas in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: lomond in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: ibm-cos-sdk in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: requests in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: pytz>=2011k in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from pandas->watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: numpy>=1.9.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from pandas->watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: python-dateutil>=2.5.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from pandas->watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: six>=1.10.0 in /usr/local/src/conda3_runtime.v37/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from lomond->watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: ibm-cos-sdk-core==2.*,>=2.0.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: chardet<3.1.0,>=3.0.2 in /usr/local/src/conda3_runtime.v37/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from requests->watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: idna<2.8,>=2.5 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s081-fcdcc2c8c4a157-70f20d2e11bc/.local/lib/python3.5/site-packages (from requests->watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: docutils>=0.10 in /usr/local/src/conda3_runtime.v37/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client==1.0.260)\nRequirement already up-to-date: jmespath<1.0.0,>=0.7.1 in /usr/local/src/conda3_runtime.v37/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client==1.0.260)\n"
                }
            ], 
            "execution_count": 175
        }, 
        {
            "source": "**Note**: Please restart the kernel (Kernel -> Restart)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"introduction\"></a>\n## 1. Introduction\n\nThis notebook defines, trains and deploys the model that recommends specific Action for unstatisfied customers.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"load\"></a>\n## 2. Load and explore data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this section you will load the data as an Apache Spark DataFrame and perform a basic exploration.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Read data into Spark DataFrame from DB2 database and show sample record.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n\n# @hidden_cell\n# The following code is used to access your data and contains your credentials.\n# You might want to remove those credentials before you share your notebook.\n\nproperties_c166344e776040b39f477655199897f8 = {\n    'driver': 'com.ibm.db2.jcc.DB2Driver',\n    'jdbcurl': 'jdbc:db2://dashdb-entry-yp-dal10-01.services.dal.bluemix.net:50000/BLUDB',\n    'user': 'dash5120',\n    'password': 'G5_CehiL4_Ux'\n}\n\ntable_name = 'CAR_RENTAL_TRAINING'\ndf_data = spark.read.jdbc(properties_db2['jdbcurl'], table='.'.join(['DASH5120', table_name]), properties=properties_db2)\ndf_data.head()\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Row(ID=74, Gender='Male', Status='M', Children=1, Age=Decimal('26.26'), Customer_Status='Active', Car_Owner='No', Customer_Service='no wait for pick up and drop off was great, help with luggage, face to face directions to hotel, recommended entertainment for area.', Satisfaction=1, Business_Area='Product: Information', Action='NA')"
                    }, 
                    "execution_count": 197, 
                    "metadata": {}
                }
            ], 
            "execution_count": 197
        }, 
        {
            "source": "df_data.printSchema()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- ID: integer (nullable = true)\n |-- Gender: string (nullable = true)\n |-- Status: string (nullable = true)\n |-- Children: integer (nullable = true)\n |-- Age: decimal(6,2) (nullable = true)\n |-- Customer_Status: string (nullable = true)\n |-- Car_Owner: string (nullable = true)\n |-- Customer_Service: string (nullable = true)\n |-- Satisfaction: integer (nullable = true)\n |-- Business_Area: string (nullable = true)\n |-- Action: string (nullable = true)\n\n"
                }
            ], 
            "execution_count": 198
        }, 
        {
            "source": "**Tip:** Code above can be inserted using Data menu.  You have to select `Insert SparkSession DataFrame` option.\n\n**Note:** Inserted code is modified to work with code in cells below.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "As you can see, the data contains eleven fields. `Action` field is the one you would like to predict using feedback data in `Customer_Service` field.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "print(\"Number of records: \" + str(df_data.count()))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of records: 482\n"
                }
            ], 
            "execution_count": 199
        }, 
        {
            "source": "As you can see, the data set contains 243 records.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df_data.select('Business_area').groupBy('Business_area').count().show(truncate=False)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+----------------------------------+-----+\n|Business_area                     |count|\n+----------------------------------+-----+\n|Service: Accessibility            |26   |\n|Product: Functioning              |150  |\n|Service: Attitude                 |24   |\n|Service: Orders/Contracts         |32   |\n|Product: Availability/Variety/Size|38   |\n|Product: Pricing and Billing      |24   |\n|Product: Information              |8    |\n|Service: Knowledge                |180  |\n+----------------------------------+-----+\n\n"
                }
            ], 
            "execution_count": 241
        }, 
        {
            "source": "df_data.select('Action').groupBy('Action').count().show(truncate=False)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-------------------------+-----+\n|Action                   |count|\n+-------------------------+-----+\n|NA                       |274  |\n|Voucher                  |42   |\n|Premium features         |30   |\n|On-demand pickup location|56   |\n|Free Upgrade             |80   |\n+-------------------------+-----+\n\n"
                }
            ], 
            "execution_count": 200
        }, 
        {
            "source": "<a id=\"model\"></a>\n## 3. Create an Apache Spark machine learning model\n\nIn this section you will learn how to:\n\n- [3.1 Prepare data for training a model](#prep)\n- [3.2 Create an Apache Spark machine learning pipeline](#pipe)\n- [3.3 Train a model](#train)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"prep\"></a>\n### 3.1 Prepare data for training a model\n\nIn this subsection you will split your data into: train and test data set.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "train_data, test_data = df_data.randomSplit([0.8, 0.2], 24)\n\nprint(\"Number of training records: \" + str(train_data.count()))\nprint(\"Number of testing records : \" + str(test_data.count()))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of training records: 387\nNumber of testing records : 95\n"
                }
            ], 
            "execution_count": 201
        }, 
        {
            "source": "### 3.2 Create the pipeline<a id=\"pipe\"></a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this section you will create an Apache Spark machine learning pipeline and then train the model.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler, HashingTF, IDF, Tokenizer\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml import Pipeline, Model", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 202
        }, 
        {
            "source": "In the following step, use the StringIndexer transformer to convert all the string fields to numeric ones.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "string_indexer_gender = StringIndexer(inputCol=\"Gender\", outputCol=\"gender_ix\")\nstring_indexer_customer_status = StringIndexer(inputCol=\"Customer_Status\", outputCol=\"customer_status_ix\")\nstring_indexer_status = StringIndexer(inputCol=\"Status\", outputCol=\"status_ix\")\nstring_indexer_owner = StringIndexer(inputCol=\"Car_Owner\", outputCol=\"owner_ix\")\nstring_business_area = StringIndexer(inputCol=\"Business_Area\", outputCol=\"area_ix\")", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 203
        }, 
        {
            "source": "assembler = VectorAssembler(inputCols=[\"gender_ix\", \"customer_status_ix\", \"status_ix\", \"owner_ix\", \"area_ix\", \"Children\", \"Age\", \"Satisfaction\"], outputCol=\"features\")", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 210
        }, 
        {
            "source": "string_indexer_action = StringIndexer(inputCol=\"Action\", outputCol=\"label\").fit(df_data)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 211
        }, 
        {
            "source": "label_action_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=string_indexer_action.labels)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 212
        }, 
        {
            "source": "dt_action = DecisionTreeClassifier()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 213
        }, 
        {
            "source": "pipeline_action = Pipeline(stages=[string_indexer_gender, string_indexer_customer_status, string_indexer_status, string_indexer_action, string_indexer_owner, string_business_area, assembler, dt_action, label_action_converter])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 214
        }, 
        {
            "source": "model_action = pipeline_action.fit(train_data)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 215
        }, 
        {
            "source": "predictions_action = model_action.transform(test_data)\npredictions_action.select('Business_Area','Action','probability','predictedLabel').show(2)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------------------+------------+--------------------+--------------+\n|       Business_Area|      Action|         probability|predictedLabel|\n+--------------------+------------+--------------------+--------------+\n|Product: Availabi...|Free Upgrade|[0.0,1.0,0.0,0.0,...|  Free Upgrade|\n|Product: Availabi...|     Voucher|[0.0,0.0,0.0,1.0,...|       Voucher|\n+--------------------+------------+--------------------+--------------+\nonly showing top 2 rows\n\n"
                }
            ], 
            "execution_count": 216
        }, 
        {
            "source": "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions_action)\n\nprint(\"Accuracy = %g\" % accuracy)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Accuracy = 0.873684\n"
                }
            ], 
            "execution_count": 218
        }, 
        {
            "source": "<a id=\"persistence\"></a>\n## 4. Store the model in the repository", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "In this section you will store trained model to Watson Machine Learning repository. When model is stored some metada is optional, however we provide it to be able to configure Continuous Learning System.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 219
        }, 
        {
            "source": "We need Watson Machine Learning credentials to be able to store model in repository.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# @hidden_cell\n# How to get associated service credentials\n\nwml_credentials = {\n  \"instance_id\": \"000263d8-04e0-4060-ad69-fcfe40069018\",\n  \"password\": \"7419325b-3de4-476c-94cb-4b158fa335b0\",\n  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n  \"username\": \"cdc4b5da-8380-42f1-bd82-da044b283959\"\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 220
        }, 
        {
            "source": "client = WatsonMachineLearningAPIClient(wml_credentials)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 221
        }, 
        {
            "source": "client.version", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "'1.0.260'"
                    }, 
                    "execution_count": 222, 
                    "metadata": {}
                }
            ], 
            "execution_count": 222
        }, 
        {
            "source": "### 4.2 Save the pipeline and model<a id=\"save\"></a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "db2_service_credentials = {\n  \"hostname\": \"dashdb-entry-yp-dal10-01.services.dal.bluemix.net\",\n  \"password\": \"G5_CehiL4_Ux\",\n  \"https_url\": \"https://dashdb-entry-yp-dal10-01.services.dal.bluemix.net:8443\",\n  \"port\": 50000,\n  \"ssldsn\": \"DATABASE=BLUDB;HOSTNAME=dashdb-entry-yp-dal10-01.services.dal.bluemix.net;PORT=50001;PROTOCOL=TCPIP;UID=dash5120;PWD=G5_CehiL4_Ux;Security=SSL;\",\n  \"host\": \"dashdb-entry-yp-dal10-01.services.dal.bluemix.net\",\n  \"jdbcurl\": \"jdbc:db2://dashdb-entry-yp-dal10-01.services.dal.bluemix.net:50000/BLUDB\",\n  \"uri\": \"db2://dash5120:G5_CehiL4_Ux@dashdb-entry-yp-dal10-01.services.dal.bluemix.net:50000/BLUDB\",\n  \"db\": \"BLUDB\",\n  \"dsn\": \"DATABASE=BLUDB;HOSTNAME=dashdb-entry-yp-dal10-01.services.dal.bluemix.net;PORT=50000;PROTOCOL=TCPIP;UID=dash5120;PWD=G5_CehiL4_Ux;\",\n  \"username\": \"dash5120\",\n  \"ssljdbcurl\": \"jdbc:db2://dashdb-entry-yp-dal10-01.services.dal.bluemix.net:50001/BLUDB:sslConnection=true;\"\n}\n\ntraining_data_reference = {\n \"name\": \"CARS4U training reference\",\n \"connection\": db2_service_credentials,\n \"source\": {\n  \"tablename\": table_name,\n  \"type\": \"dashdb\"\n }\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 223
        }, 
        {
            "source": "model_props = {\n    client.repository.ModelMetaNames.NAME: \"CARS4U - Action Recommendation Model\",\n    client.repository.ModelMetaNames.TRAINING_DATA_REFERENCE: training_data_reference,\n    client.repository.ModelMetaNames.EVALUATION_METHOD: \"multiclass\",\n    client.repository.ModelMetaNames.EVALUATION_METRICS: [\n        {\n           \"name\": \"accuracy\",\n           \"value\": accuracy,\n           \"threshold\": 0.7\n        }\n    ]\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 224
        }, 
        {
            "source": "**Tip**: Use `client.repository.ModelMetaNames.show()` to get the list of available meta names.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "published_model_details = client.repository.store_model(model=model_action, meta_props=model_props, training_data=train_data, pipeline=pipeline_action)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 225
        }, 
        {
            "source": "model_uid = client.repository.get_model_uid(published_model_details)\nprint(model_uid)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "3eccfe5a-8c74-4cb3-98ba-0f604a224836\n"
                }
            ], 
            "execution_count": 226
        }, 
        {
            "source": "<a id=\"deploy\"></a>\n## 5. Deploy model in the IBM Cloud", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "You can use following command to create online deployment in cloud.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "deployment_details = client.deployments.create(model_uid=model_uid, name='CARS4U - Action Model Deployment')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '3eccfe5a-8c74-4cb3-98ba-0f604a224836' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='e2b5927f-9a0d-49dc-b731-39272f08b6bb'\n------------------------------------------------------------------------------------------------\n\n\n"
                }
            ], 
            "execution_count": 227
        }, 
        {
            "source": "You can use deployed model to score new data using scoring endpoint.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "scoring_url = client.deployments.get_scoring_url(deployment_details)\nprint(scoring_url)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "https://us-south.ml.cloud.ibm.com/v3/wml_instances/000263d8-04e0-4060-ad69-fcfe40069018/deployments/e2b5927f-9a0d-49dc-b731-39272f08b6bb/online\n"
                }
            ], 
            "execution_count": 228
        }, 
        {
            "source": "<a id=\"logging\"></a>\n## 6. Payload logging", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Payload logging feature allows to store all scoring requests and scoring responses in postgress database.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 6.1 Setup", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "deployment_uid = client.deployments.get_uid(deployment_details)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 229
        }, 
        {
            "source": "# @hidden_cell\npostgres_connection = {\n  'database':'compose',\n  'password':\"\"\"WHDHTGJYSXKJTMET\"\"\",\n  'port':'47860',\n  'host':'sl-us-south-1-portal.28.dblayer.com',\n  'username':'admin'\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 234
        }, 
        {
            "source": "payload_data_reference = {\n    \"type\": \"postgresql\",\n    \"location\": {\n        \"tablename\": \"public.cars4u_action_recommendation_payload\"\n    },\n    \"connection\": {\n            \"uri\": \"postgres://{username}:{password}@{host}:{port}/{database}\".format(**postgres_connection)\n        }\n}\nprint(payload_data_reference)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "{'connection': {'uri': 'postgres://admin:WHDHTGJYSXKJTMET@sl-us-south-1-portal.28.dblayer.com:47860/compose'}, 'location': {'tablename': 'public.cars4u_action_recommendation_payload'}, 'type': 'postgresql'}\n"
                }
            ], 
            "execution_count": 235
        }, 
        {
            "source": "payload_metadata = {\n    client.deployments.PayloadLoggingMetaNames.PAYLOAD_DATA_REFERENCE: payload_data_reference\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 236
        }, 
        {
            "source": "config_details = client.deployments.setup_payload_logging(deployment_uid, meta_props=payload_metadata)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 237
        }, 
        {
            "source": "### 6.2 Score", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "fields = ['ID', 'Gender', 'Status', 'Children', 'Age', 'Customer_Status','Car_Owner', 'Customer_Service', 'Business_Area', 'Satisfaction']\nvalues = [3785, 'Male', 'S', 1, 17, 'Inactive', 'Yes', 'The car should have been brought to us instead of us trying to find it in the lot.', 'Product: Information', 0]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 244
        }, 
        {
            "source": "import json\n\npayload_scoring = {\"fields\": fields,\"values\": [values]}\nscoring_response = client.deployments.score(scoring_url, payload_scoring)\n\nprint(json.dumps(scoring_response, indent=3))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "{\n   \"fields\": [\n      \"ID\",\n      \"Gender\",\n      \"Status\",\n      \"Children\",\n      \"Age\",\n      \"Customer_Status\",\n      \"Car_Owner\",\n      \"Customer_Service\",\n      \"Business_Area\",\n      \"Satisfaction\",\n      \"Action\",\n      \"gender_ix\",\n      \"customer_status_ix\",\n      \"status_ix\",\n      \"label\",\n      \"owner_ix\",\n      \"area_ix\",\n      \"features\",\n      \"rawPrediction\",\n      \"probability\",\n      \"prediction\",\n      \"predictedLabel\"\n   ],\n   \"values\": [\n      [\n         3785,\n         \"Male\",\n         \"S\",\n         1,\n         17.0,\n         \"Inactive\",\n         \"Yes\",\n         \"The car should have been brought to us instead of us trying to find it in the lot.\",\n         \"Product: Information\",\n         0,\n         \"NA\",\n         0.0,\n         1.0,\n         1.0,\n         0.0,\n         1.0,\n         7.0,\n         [\n            0.0,\n            1.0,\n            1.0,\n            1.0,\n            7.0,\n            1.0,\n            17.0,\n            0.0\n         ],\n         [\n            0.0,\n            0.0,\n            7.0,\n            0.0,\n            0.0\n         ],\n         [\n            0.0,\n            0.0,\n            1.0,\n            0.0,\n            0.0\n         ],\n         2.0,\n         \"On-demand pickup location\"\n      ]\n   ]\n}\n"
                }
            ], 
            "execution_count": 245
        }, 
        {
            "source": "<a id=\"learning\"></a>\n## 7. Continuous Learning System", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 7.1 Setup", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# @hidden_cell\n\nspark_credentials = {\n  \"tenant_id\": \"s081-fcdcc2c8c4a157-70f20d2e11bc\",\n  \"tenant_id_full\": \"9cb8e642-e850-49f8-9081-fcdcc2c8c4a1_5d5b82ce-01cb-4b9f-9c57-70f20d2e11bc\",\n  \"cluster_master_url\": \"https://spark.bluemix.net\",\n  \"tenant_secret\": \"7d6bb1ff-3965-4d41-8182-6156660e8194\",\n  \"instance_id\": \"9cb8e642-e850-49f8-9081-fcdcc2c8c4a1\",\n  \"plan\": \"ibm.SparkService.PayGoPersonal\"\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 246
        }, 
        {
            "source": "feedback_data_reference = {\n \"name\": \"Cars4You feedback data\",\n \"connection\": db2_service_credentials,\n \"source\": {\n  \"tablename\": \"CAR_RENTAL_FEEDBACK\",\n  \"type\": \"dashdb\"\n }\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 247
        }, 
        {
            "source": "system_config = {\n    client.learning_system.ConfigurationMetaNames.FEEDBACK_DATA_REFERENCE: feedback_data_reference,\n    client.learning_system.ConfigurationMetaNames.MIN_FEEDBACK_DATA_SIZE: 10,\n    client.learning_system.ConfigurationMetaNames.SPARK_REFERENCE: spark_credentials,\n    client.learning_system.ConfigurationMetaNames.AUTO_RETRAIN: \"never\",\n    client.learning_system.ConfigurationMetaNames.AUTO_REDEPLOY: \"never\"\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 248
        }, 
        {
            "source": "**Note:** You can update RETRAIN option to either `always` or `conditionally`. The REDEPLOY option can be also updated `always` or `conditionally`. `conditionally` means that action will happen only if new model version is better than previosly used one.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "learning_system_details = client.learning_system.setup(model_uid=model_uid, meta_props=system_config)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 249
        }, 
        {
            "source": "### 7.2 Run learning system iteration", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "run_details = client.learning_system.run(model_uid, asynchronous=False)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\n\n#######################################################################\n\nSynchronous run for uid: 'a2584808-8779-44dc-9991-4f50e6069f83' started\n\n#######################################################################\n\n\nINITIALIZED...\nRUNNING..........\nCOMPLETED\n\n\n--------------------------------------------------------------------------------------------\nSuccessfully finished learning iteration run, run_uid='a2584808-8779-44dc-9991-4f50e6069f83'\n--------------------------------------------------------------------------------------------\n\n\n"
                }
            ], 
            "execution_count": 250
        }, 
        {
            "source": "client.learning_system.list()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "------------------------------------  ------------------------------------  ---------  -------  --------  -----------------\nMODEL GUID                            MODEL NAME                            FRAMEWORK  RETRAIN  REDEPLOY  MIN FEEDBACK ROWS\na1e4cde1-c6de-4bd3-b23d-72106103dd0e  CARS4U - Action Recommendation Model  mllib-2.1  never    never     10\n3eccfe5a-8c74-4cb3-98ba-0f604a224836  CARS4U - Action Recommendation Model  mllib-2.1  never    never     10\n------------------------------------  ------------------------------------  ---------  -------  --------  -----------------\n"
                }
            ], 
            "execution_count": 251
        }, 
        {
            "source": "client.learning_system.list_runs(model_uid)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "------------------------------------  ------------------------  ---------\nRUN GUID                              CREATED                   STATE\na2584808-8779-44dc-9991-4f50e6069f83  2018-07-25T08:57:45.924Z  COMPLETED\n------------------------------------  ------------------------  ---------\n"
                }
            ], 
            "execution_count": 252
        }, 
        {
            "source": "client.learning_system.list_metrics(model_uid)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "----------  ------------------------  -----------  ------------------  --------------  -----------------------------------\nPHASE       TIMESTAMP                 METRIC NAME  METRIC VALUE        METRIC THRESH.  VERSION\nsetup       2018-07-25T08:49:04.523Z  accuracy     0.8736842105263158  0.7             e83ca56b-d276-4603-909c-6b74e3f3a13\nmonitoring  2018-07-25T08:58:56.703Z  accuracy     0.25                0.7             e83ca56b-d276-4603-909c-6b74e3f3a13\n----------  ------------------------  -----------  ------------------  --------------  -----------------------------------\n"
                }
            ], 
            "execution_count": 253
        }, 
        {
            "source": "---", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}